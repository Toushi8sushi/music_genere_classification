{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32227a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd \n",
    "from tqdm import tqdm #for progress bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb777fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path='T:\\\\TOSHITH\\\\PROGRAMMING\\\\music_genere_classification\\\\genres_original'\n",
    "output_file_path='T:\\\\TOSHITH\\\\PROGRAMMING\\\\music_genere_classification\\\\genres_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078c3b8",
   "metadata": {},
   "source": [
    "### Step 1 Define all the audio extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3003492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_envolope(signal,N,FRAME_SIZE,HOP_SIZE):\n",
    "    return np.array([max(signal[i:i+FRAME_SIZE]) for i in range(0,N,HOP_SIZE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073e4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_energy_ratio_calculator(split_freq,spectogram,sample_rate):\n",
    "    freq_range=sample_rate/2\n",
    "    freq_range_per_bin= freq_range/spectogram.shape[0]\n",
    "    freq_bin_of_split_freq=int(np.floor(split_freq/freq_range_per_bin))\n",
    "    #what bin does our split freq lie in so that we can get ratio of above and below \n",
    "\n",
    "    power_specturm=np.abs(spectogram)**2\n",
    "    power_specturm=power_specturm.T\n",
    "\n",
    "    band_energy_series=[]\n",
    "\n",
    "    for freq_in_frame in power_specturm:\n",
    "        sum_low_freq= np.sum(freq_in_frame[:freq_bin_of_split_freq])\n",
    "        sum_high_freq= np.sum(freq_in_frame[freq_bin_of_split_freq:])\n",
    "\n",
    "        if sum_high_freq == 0:\n",
    "            band_energy_series.append(0)  # or 0, or some default value\n",
    "        else:\n",
    "            band_energy_series.append(sum_low_freq / sum_high_freq)\n",
    "\n",
    "    return np.array(band_energy_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418f2d3",
   "metadata": {},
   "source": [
    "#### Note: all other functions are builtin in librosa "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291a96f",
   "metadata": {},
   "source": [
    "### Step 2 processing all files and storing the output in a csv file using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a71901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be a power of 2 for FFT algorithm, and a frame size of 4096 equals to 200ms of audio length \n",
    "FRAME_SIZE=4096 \n",
    "#to create overlapping frame for future calculations  \n",
    "HOP_SIZE=2048  \n",
    "#we define an arbitrairy band F=2500Hz to split to calculate the Band energy ratio \n",
    "SPLIT_FREQ=2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733df257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing genres:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing genres:  50%|█████     | 5/10 [01:23<01:25, 17.09s/it]C:\\Users\\toshi\\AppData\\Local\\Temp\\ipykernel_77928\\1520560381.py:21: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, Fs = librosa.load(audio_path)\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load T:\\TOSHITH\\PROGRAMMING\\music_genere_classification\\genres_original\\jazz\\jazz.00054.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing genres: 100%|██████████| 10/10 [02:47<00:00, 16.79s/it]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_file_path, exist_ok=True)\n",
    "\n",
    "genere_names = sorted(os.listdir(input_file_path))\n",
    "\n",
    "#we want all audio files to be of the same length therefore we crop the audio files to 30s\n",
    "no_of_samples=22050*30 #sampling rate multiplied by time \n",
    "\n",
    "for label, genere_name in enumerate(tqdm(genere_names, desc=\"Processing genres\")):\n",
    "    genere_path = os.path.join(input_file_path, genere_name)\n",
    "    if not os.path.isdir(genere_path):\n",
    "        continue\n",
    "\n",
    "    # Create the output genre folder\n",
    "    output_genere_path = os.path.join(output_file_path, genere_name)\n",
    "    os.makedirs(output_genere_path, exist_ok=True)\n",
    "\n",
    "    audio_files = os.listdir(genere_path)\n",
    "    for Audio_file_name in tqdm(audio_files, desc=f\"Processing {genere_name}\", leave=False):\n",
    "        audio_path = os.path.join(genere_path, Audio_file_name)\n",
    "        try:\n",
    "            audio, Fs = librosa.load(audio_path)\n",
    "            audio=audio[:no_of_samples] #cropping audio to 30s\n",
    "\n",
    "            amp_envelope = amplitude_envolope(audio, len(audio), FRAME_SIZE, HOP_SIZE)\n",
    "            rms_energy = librosa.feature.rms(y=audio, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "            zero_cr = librosa.feature.zero_crossing_rate(y=audio, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "            sfose = librosa.onset.onset_strength(y=audio, sr=Fs, hop_length=HOP_SIZE)\n",
    "            mfcc = librosa.feature.mfcc(y=audio, n_mfcc=13, sr=Fs, hop_length=HOP_SIZE, n_fft=FRAME_SIZE)\n",
    "            mfcc = np.mean(mfcc, axis=0)\n",
    "            delta_mfcc = librosa.feature.delta(mfcc)\n",
    "            delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "            spec_centroid = librosa.feature.spectral_centroid(y=audio, sr=Fs, hop_length=HOP_SIZE, n_fft=FRAME_SIZE)[0]\n",
    "            spec_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=Fs, hop_length=HOP_SIZE, n_fft=FRAME_SIZE)[0]\n",
    "            spectrogram = librosa.stft(audio, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "            band_energy_ratio = band_energy_ratio_calculator(SPLIT_FREQ, spectrogram, Fs)\n",
    "\n",
    "            # Create DataFrame \n",
    "            df = pd.DataFrame({\n",
    "                \"Amplitude_Envelope\": amp_envelope,\n",
    "                \"RMS_Energy\": rms_energy,\n",
    "                \"Zero_Crossing_Rate\": zero_cr,\n",
    "                \"SFOSE\": sfose,\n",
    "                \"MFCC\": mfcc,\n",
    "                \"Delta_MFCC\": delta_mfcc,\n",
    "                \"Delta2_MFCC\": delta2_mfcc,\n",
    "                \"Spectral_Centroid\": spec_centroid,\n",
    "                \"Spectral_Bandwidth\": spec_bandwidth,\n",
    "                \"Band_Energy_Ratio\": band_energy_ratio,\n",
    "            })\n",
    "\n",
    "            # Save to CSV in same folder structure\n",
    "            csv_name = os.path.splitext(Audio_file_name)[0] + \"_features.csv\"\n",
    "            csv_path = os.path.join(output_genere_path, csv_name)\n",
    "            df.to_csv(csv_path, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {audio_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38388cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: blues, Processed files: 100\n",
      "Genre: classical, Processed files: 100\n",
      "Genre: country, Processed files: 100\n",
      "Genre: disco, Processed files: 100\n",
      "Genre: hiphop, Processed files: 100\n",
      "Genre: jazz, Processed files: 99\n",
      "Genre: metal, Processed files: 100\n",
      "Genre: pop, Processed files: 100\n",
      "Genre: reggae, Processed files: 100\n",
      "Genre: rock, Processed files: 100\n"
     ]
    }
   ],
   "source": [
    "#verifying that the files are processed properly \n",
    "genere_names = [name for name in os.listdir(output_file_path)\n",
    "                if os.path.isdir(os.path.join(output_file_path, name))]\n",
    "genere_names.sort()\n",
    "\n",
    "# Count files in each genre subfolder\n",
    "for genere_name in genere_names:\n",
    "    genere_path = os.path.join(output_file_path, genere_name)\n",
    "    # Count only files, not directories\n",
    "    file_count = len([name for name in os.listdir(genere_path)\n",
    "                      if os.path.isfile(os.path.join(genere_path, name))])\n",
    "    print(f\"Genre: {genere_name}, Processed files: {file_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
